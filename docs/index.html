<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AdaFlow: Efficient Long Video Editing via Adaptive Attention Slimming And Keyframe Selection</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./assets/css/bulma.min.css">
  <link rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
      crossorigin="anonymous" referrerpolicy="no-referrer" />
  <link rel="stylesheet" href="./assets/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./assets/css/index.css">
</head>

<script>
MathJax = {
  tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
  svg: { fontCache: 'global' }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

<body>

<!-- Title + Authors -->
<section class="hero">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-1">AdaFlow: Efficient Long Video Editing via Adaptive Attention Slimming And Keyframe Selection</h1>
      <div class="is-size-5 publication-authors">
        <span class="author-block">Shuheng Zhang<sup>1,2</sup>,</span>
        <span class="author-block">Yuqi Liu<sup>1</sup>,</span>
        <span class="author-block">Hongbo Zhou<sup>1</sup>,</span>
        <span class="author-block">Jun Peng<sup>3</sup>,</span>
        <span class="author-block">Yiyi Zhou<sup>1,2</sup>,</span>
        <span class="author-block">Xiaoshuai Sun<sup>1,2</sup>,</span>
        <span class="author-block">Rongrong Ji<sup>1,2</sup></span>
      </div>
      <div class="is-size-5 publication-authors">
        <span class="author-block"><sup>1</sup>Key Laboratory of Multimedia Trusted Perception and Efficient Computing, Ministry of Education of China, Xiamen University,</span>
        <span class="author-block"><sup>2</sup>Institute of Artificial Intelligence, Xiamen University,</span>
        <span class="author-block"><sup>3</sup>Peng Cheng Laboratory</span>
      </div>

      <!-- Buttons -->
      <div class="publication-links" style="margin-top: 1rem;">
        <span class="link-block">
          <a href="https://arxiv.org/abs/2502.05433"
             class="external-link button is-normal is-rounded is-dark"
             target="_blank" rel="noopener noreferrer">
            <span class="icon"><i class="ai ai-arxiv" aria-hidden="true"></i></span>
            <span>arXiv</span>
          </a>
        </span>

        <span class="link-block">
          <a href="https://github.com/jidantang55/AdaFlow"
             class="external-link button is-normal is-rounded is-dark"
             target="_blank" rel="noopener noreferrer">
            <span class="icon"><i class="fab fa-github" aria-hidden="true"></i></span>
            <span>Code</span>
          </a>
        </span>

        <span class="link-block">
          <a href="https://huggingface.co/datasets/zhangsh2001/LongV-EVAL"
             class="external-link button is-normal is-rounded is-dark"
             target="_blank" rel="noopener noreferrer">
            <span class="icon"><i class="fas fa-database" aria-hidden="true"></i></span>
            <span>LongV-EVAL</span>
          </a>
        </span>

        <span class="link-block">
          <a href="./assets/pdfs/Appendix.pdf"
             class="external-link button is-normal is-rounded is-dark"
             target="_blank" rel="noopener noreferrer">
            <span class="icon"><i class="fas fa-file-pdf" aria-hidden="true"></i></span>
            <span>Appendix</span>
          </a>
        </span>
      </div>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Abstract</h2>
    <div class="content has-text-justified">
      <p>
      Despite great progress, text-driven long video editing is still notoriously challenging mainly due to excessive memory overhead.
      Although recent efforts have simplified this task into a two-step process of keyframe translation and interpolation generation,
      the token-wise keyframe translation still plagues the upper limit of video length.
      In this paper, we propose a novel and training-free approach towards efficient and effective long video editing, termed
      <b><i>AdaFlow</i></b>.
      We first reveal that not all tokens of video frames hold equal importance for keyframe translation, based on which we propose an
      <i>Adaptive Attention Slimming</i> scheme for AdaFlow to squeeze the \( KV \) sequence, thus increasing the number of keyframes
      for translations by an order of magnitude.
      In addition, an <i>Adaptive Keyframe Selection</i> scheme is also equipped to select the representative frames for joint editing,
      further improving generation quality.
      With these innovative designs, AdaFlow achieves high-quality long video editing of minutes in one inference,
      <i>i.e.</i>, more than \( 1k \) frames on one A800 GPU, which is about ten times longer than the compared methods,
      <i>e.g.</i>, TokenFlow.
      To validate AdaFlow, we also build a new benchmark for long video editing with high-quality annotations, termed
      <b><i>LongV-EVAL</i></b>.
      </p>
    </div>
  </div>
</section>

<!-- Key Contributions -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Key Contributions</h2>
    <div class="content has-text-justified">
      <p>
      Our proposed AdaFlow method achieves a <b>significant efficiency improvement of over 40%</b> compared to state-of-the-art methods
      while maintaining comparable video editing quality. This breakthrough is made possible through our innovative Adaptive Attention
      Slimming and Keyframe Selection mechanisms, which intelligently reduce computational overhead without compromising visual fidelity.
      </p>
    </div>

    <div class="columns is-centered">
      <div class="column is-full has-text-centered">
        <figure class="image">
          <img src="./assets/images/tabel1.png" alt="Efficiency Comparison Table" style="max-width: 80%; margin: 0 auto;">
        </figure>
      </div>
    </div>
  </div>
</section>

<!-- Videos -->
<section class="section" id="short_videos">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Comparison on Short Videos</h2>

    <!-- 添加的视频描述文字 -->
    <div class="content has-text-justified" style="margin-bottom: 2rem;">
      <p>
      Our method is compared with TokenFlow's official sample. Although our method was designed for long videos, it still has advantages in terms of efficiency and quality when applied to such shorter videos. It should be noted that since we and TokenFlow used the same pre-trained weights and image editing methods, the generated results are somewhat similar. Once again, it should be emphasized that the main contribution of this paper lies in terms of efficiency, rather than in the outstanding generation results.
      </p>
    </div>

    <div class="columns is-centered">
      <div class="column has-text-centered">
        <video autoplay muted loop controls playsinline width="1000">
          <source src="./assets/videos/video_short.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section" id="long_videos">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Comparison on Long Videos</h2>

    <!-- 添加的视频描述文字 -->
    <div class="content has-text-justified" style="margin-bottom: 2rem;">
      <p>
      Our method is compared with TokenFlow on the long video samples. Our method can edit long videos all at once on a single GPU, while other methods can only edit them segment by segment, which would seriously compromise the temporal consistency. Moreover, our method also has significantly shorter processing time.
      </p>
    </div>

    <div class="columns is-centered">
      <div class="column has-text-centered">
        <video autoplay muted loop controls playsinline width="1000">
          <source src="./assets/videos/video_long.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section" id="10k_videos">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Extremely Long Videos</h2>

    <!-- 添加的视频描述文字 -->
    <div class="content has-text-justified" style="margin-bottom: 2rem;">
      <p>
      Thanks to the adaptive keyframe selection, for relatively static videos, we can edit very long videos in one go. For instance, this video has over ten thousand frames, and we can still complete the editing process on a single GPU.
      </p>
    </div>

    <div class="columns is-centered">
      <div class="column has-text-centered">
        <video autoplay muted loop controls playsinline width="1000">
          <source src="./assets/videos/video_10k.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>
